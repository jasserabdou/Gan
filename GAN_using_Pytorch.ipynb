{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "-a7Brgqms-tz"
      },
      "outputs": [],
      "source": [
        "# Import the necessary modules\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn \n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "-5n51KsNbVN2"
      },
      "outputs": [],
      "source": [
        "# Define the hyperparameters\n",
        "batch_size = 128        # Higher batch size to better utilize GPU memory\n",
        "latent_dim = 100        # Dimension of the latent space (this is fine for MNIST)\n",
        "num_epochs = 100        # Training for 100 epochs is often enough for MNIST\n",
        "lr = 0.0002             # This learning rate works well with Adam optimizer\n",
        "beta1 = 0.5             # A common choice for GANs to help with stable convergence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "XMvqc40fU4Af"
      },
      "outputs": [],
      "source": [
        "# Create a directory images if not exists\n",
        "if not os.path.exists(\"images\"):\n",
        "    os.makedirs(\"images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "FlSvUC0ItDAx"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\train-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: certificate has expired (_ssl.c:1007)>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100.0%"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting ./data\\MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data\\MNIST\\raw\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# Create the dataloader for MNIST dataset\n",
        "transform = transforms.Compose(\n",
        "    [\n",
        "        transforms.ToTensor(),  # Convert the images to tensors\n",
        "        transforms.Normalize((0.5,), (0.5,)),  # Normalize the images to [-1, 1] range\n",
        "    ]\n",
        ")\n",
        "dataset = torchvision.datasets.MNIST(\n",
        "    root=\"./data\", train=True, download=True, transform=transform\n",
        ")\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    dataset, batch_size=batch_size, shuffle=True, num_workers=2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "6EJ2r3icbfsn"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cuda\n"
          ]
        }
      ],
      "source": [
        "# Define the device to use (GPU or CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WSec1Xvnzisb"
      },
      "outputs": [],
      "source": [
        "# Define the generator network\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "        # A sequential container of layers\n",
        "        self.main = nn.Sequential(\n",
        "            # A linear layer that maps the latent vector to 256*7*7 features\n",
        "            nn.Linear(latent_dim, 256 * 7 * 7),\n",
        "            # A batch normalization layer to stabilize the training\n",
        "            nn.BatchNorm1d(256 * 7 * 7),\n",
        "            # A leaky ReLU activation function with negative slope 0.2\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # Reshape the features to a 4D tensor of shape (batch_size, 256, 7, 7)\n",
        "            nn.Unflatten(1, (256, 7, 7)),\n",
        "            # A transposed convolution layer that upsamples the features to 128*14*14\n",
        "            nn.ConvTranspose2d(256, 128, 4, 2, 1),\n",
        "            # A batch normalization layer\n",
        "            nn.BatchNorm2d(128),\n",
        "            # A leaky ReLU activation function\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # A transposed convolution layer that upsamples the features to 64*28*28\n",
        "            nn.ConvTranspose2d(128, 64, 4, 2, 1),\n",
        "            # A batch normalization layer\n",
        "            nn.BatchNorm2d(64),\n",
        "            # A leaky ReLU activation function\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # A transposed convolution layer that upsamples the features to 1*28*28\n",
        "            nn.ConvTranspose2d(64, 1, 3, 1, 1),\n",
        "            # A tanh activation function to output values in [-1, 1] range\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # The forward pass of the generator network\n",
        "        return self.main(x)\n",
        "\n",
        "\n",
        "# Define the discriminator network\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Discriminator, self).__init__()\n",
        "        # A sequential container of layers\n",
        "        self.main = nn.Sequential(\n",
        "            # A convolution layer that downsamples the images to 64*14*14 features\n",
        "            nn.Conv2d(1, 64, 4, 2, 1),\n",
        "            # A leaky ReLU activation function with negative slope 0.2\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # A convolution layer that downsamples the features to 128*7*7 features\n",
        "            nn.Conv2d(64, 128, 4, 2, 1),\n",
        "            # A batch normalization layer to stabilize the training\n",
        "            nn.BatchNorm2d(128),\n",
        "            # A leaky ReLU activation function\n",
        "            nn.LeakyReLU(0.2),\n",
        "            # Flatten the features to a 1D tensor of shape (batch_size, 128*7*7)\n",
        "            nn.Flatten(),\n",
        "            # A linear layer that maps the features to a single output value\n",
        "            nn.Linear(128 * 7 * 7, 1),\n",
        "            # A sigmoid activation function to output a probability in [0, 1] range\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # The forward pass of the discriminator network\n",
        "        return self.main(x)\n",
        "\n",
        "\n",
        "# Create an instance of the generator and the discriminator networks\n",
        "generator = Generator().to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "\n",
        "# Define the loss function (binary cross entropy)\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "\n",
        "# Define the optimizers for the generator and the discriminator\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(beta1, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(beta1, 0.999))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jr_UX-MktLP5"
      },
      "outputs": [],
      "source": [
        "# Define a function to generate a batch of latent vectors\n",
        "def generate_latent_vectors(batch_size, latent_dim):\n",
        "    # Generate a batch of random vectors from a normal distribution\n",
        "    return torch.randn(batch_size, latent_dim, device=device)\n",
        "\n",
        "\n",
        "# Define a function to generate a batch of fake labels\n",
        "def generate_fake_labels(batch_size):\n",
        "    # Generate a batch of zeros\n",
        "    return torch.zeros(batch_size, device=device)\n",
        "\n",
        "\n",
        "# Define a function to generate a batch of real labels\n",
        "def generate_real_labels(batch_size):\n",
        "    # Generate a batch of ones\n",
        "    return torch.ones(batch_size, device=device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3M8_GPmVtWB0"
      },
      "outputs": [],
      "source": [
        "def save_images(epoch, generator, dataloader):\n",
        "    # Generate a batch of latent vectors\n",
        "    latent_vectors = generate_latent_vectors(batch_size, latent_dim).to(device)\n",
        "    # Generate a batch of fake images using the generator\n",
        "    fake_images = generator(latent_vectors)\n",
        "    # Move the fake images to the same device as the real images\n",
        "    fake_images = fake_images.to(device)\n",
        "    # Concatenate the real images and the fake images along the horizontal axis\n",
        "    images = torch.cat([real_images, fake_images], dim=3)\n",
        "    # Move the images to the CPU\n",
        "    images = images.cpu()\n",
        "    # Save the images\n",
        "    save_image(images, f\"images/image_{epoch}.png\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "jX-qgGLJtWri"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1, Batch 200, Loss_D: 0.0014, Loss_G: 6.6812\n",
            "Epoch 1, Batch 400, Loss_D: 0.0006, Loss_G: 7.6315\n",
            "Epoch 2, Batch 200, Loss_D: 0.0002, Loss_G: 8.7008\n",
            "Epoch 2, Batch 400, Loss_D: 0.0001, Loss_G: 9.2492\n",
            "Epoch 3, Batch 200, Loss_D: 0.0001, Loss_G: 9.8277\n",
            "Epoch 3, Batch 400, Loss_D: 0.0008, Loss_G: 7.7602\n",
            "Epoch 4, Batch 200, Loss_D: 0.0002, Loss_G: 9.2204\n",
            "Epoch 4, Batch 400, Loss_D: 0.0001, Loss_G: 9.6866\n",
            "Epoch 5, Batch 200, Loss_D: 0.0000, Loss_G: 10.7227\n",
            "Epoch 5, Batch 400, Loss_D: 0.0000, Loss_G: 10.6927\n",
            "Epoch 6, Batch 200, Loss_D: 0.0000, Loss_G: 11.0679\n",
            "Epoch 6, Batch 400, Loss_D: 0.0000, Loss_G: 11.1540\n",
            "Epoch 7, Batch 200, Loss_D: 0.0000, Loss_G: 11.6703\n",
            "Epoch 7, Batch 400, Loss_D: 0.0000, Loss_G: 12.0308\n",
            "Epoch 8, Batch 200, Loss_D: 0.0000, Loss_G: 12.3097\n",
            "Epoch 8, Batch 400, Loss_D: 0.0000, Loss_G: 12.4944\n",
            "Epoch 9, Batch 200, Loss_D: 0.0000, Loss_G: 12.6034\n",
            "Epoch 9, Batch 400, Loss_D: 0.0000, Loss_G: 12.6321\n",
            "Epoch 10, Batch 200, Loss_D: 0.0000, Loss_G: 12.9751\n",
            "Epoch 10, Batch 400, Loss_D: 0.0000, Loss_G: 13.1139\n",
            "Epoch 11, Batch 200, Loss_D: 0.0000, Loss_G: 13.3531\n",
            "Epoch 11, Batch 400, Loss_D: 0.0000, Loss_G: 13.5375\n",
            "Epoch 12, Batch 200, Loss_D: 0.0000, Loss_G: 13.3536\n",
            "Epoch 12, Batch 400, Loss_D: 0.0000, Loss_G: 12.9660\n",
            "Epoch 13, Batch 200, Loss_D: 0.0000, Loss_G: 13.3956\n",
            "Epoch 13, Batch 400, Loss_D: 0.0000, Loss_G: 13.2006\n",
            "Epoch 14, Batch 200, Loss_D: 0.0000, Loss_G: 13.5420\n",
            "Epoch 14, Batch 400, Loss_D: 0.0000, Loss_G: 13.8271\n",
            "Epoch 15, Batch 200, Loss_D: 0.0000, Loss_G: 14.0771\n",
            "Epoch 15, Batch 400, Loss_D: 0.0000, Loss_G: 14.2140\n",
            "Epoch 16, Batch 200, Loss_D: 0.1944, Loss_G: 2.1109\n",
            "Epoch 16, Batch 400, Loss_D: 0.1834, Loss_G: 2.3825\n",
            "Epoch 17, Batch 200, Loss_D: 0.1682, Loss_G: 2.6930\n",
            "Epoch 17, Batch 400, Loss_D: 0.3652, Loss_G: 2.1343\n",
            "Epoch 18, Batch 200, Loss_D: 0.2082, Loss_G: 2.0657\n",
            "Epoch 18, Batch 400, Loss_D: 0.2072, Loss_G: 2.0275\n",
            "Epoch 19, Batch 200, Loss_D: 0.1882, Loss_G: 1.9880\n",
            "Epoch 19, Batch 400, Loss_D: 0.2840, Loss_G: 1.9134\n",
            "Epoch 20, Batch 200, Loss_D: 0.2660, Loss_G: 1.4152\n",
            "Epoch 20, Batch 400, Loss_D: 0.2283, Loss_G: 2.1546\n",
            "Epoch 21, Batch 200, Loss_D: 0.2094, Loss_G: 2.2841\n",
            "Epoch 21, Batch 400, Loss_D: 0.2171, Loss_G: 1.5824\n",
            "Epoch 22, Batch 200, Loss_D: 0.1994, Loss_G: 2.0940\n",
            "Epoch 22, Batch 400, Loss_D: 0.2398, Loss_G: 2.2602\n",
            "Epoch 23, Batch 200, Loss_D: 0.2117, Loss_G: 3.4435\n",
            "Epoch 23, Batch 400, Loss_D: 0.2088, Loss_G: 1.9112\n",
            "Epoch 24, Batch 200, Loss_D: 0.1974, Loss_G: 2.1293\n",
            "Epoch 24, Batch 400, Loss_D: 0.2055, Loss_G: 2.5451\n",
            "Epoch 25, Batch 200, Loss_D: 0.2075, Loss_G: 2.1421\n",
            "Epoch 25, Batch 400, Loss_D: 0.2016, Loss_G: 2.0424\n",
            "Epoch 26, Batch 200, Loss_D: 0.2400, Loss_G: 2.3377\n",
            "Epoch 26, Batch 400, Loss_D: 0.1873, Loss_G: 2.3704\n",
            "Epoch 27, Batch 200, Loss_D: 0.3762, Loss_G: 2.5610\n",
            "Epoch 27, Batch 400, Loss_D: 0.2031, Loss_G: 3.0171\n",
            "Epoch 28, Batch 200, Loss_D: 0.2310, Loss_G: 2.5848\n",
            "Epoch 28, Batch 400, Loss_D: 0.3859, Loss_G: 2.7287\n",
            "Epoch 29, Batch 200, Loss_D: 0.2826, Loss_G: 1.4817\n",
            "Epoch 29, Batch 400, Loss_D: 0.1970, Loss_G: 2.5667\n",
            "Epoch 30, Batch 200, Loss_D: 0.2811, Loss_G: 1.6577\n",
            "Epoch 30, Batch 400, Loss_D: 0.3020, Loss_G: 1.8281\n",
            "Epoch 31, Batch 200, Loss_D: 0.2770, Loss_G: 2.2377\n",
            "Epoch 31, Batch 400, Loss_D: 0.2835, Loss_G: 1.8204\n",
            "Epoch 32, Batch 200, Loss_D: 0.2554, Loss_G: 2.4129\n",
            "Epoch 32, Batch 400, Loss_D: 0.2038, Loss_G: 1.9888\n",
            "Epoch 33, Batch 200, Loss_D: 0.3233, Loss_G: 1.3206\n",
            "Epoch 33, Batch 400, Loss_D: 0.2474, Loss_G: 2.1965\n",
            "Epoch 34, Batch 200, Loss_D: 0.2821, Loss_G: 2.5968\n",
            "Epoch 34, Batch 400, Loss_D: 0.2490, Loss_G: 2.0469\n",
            "Epoch 35, Batch 200, Loss_D: 0.2482, Loss_G: 2.3763\n",
            "Epoch 35, Batch 400, Loss_D: 0.2450, Loss_G: 2.3491\n",
            "Epoch 36, Batch 200, Loss_D: 0.3553, Loss_G: 4.0710\n",
            "Epoch 36, Batch 400, Loss_D: 0.2727, Loss_G: 1.8606\n",
            "Epoch 37, Batch 200, Loss_D: 0.3428, Loss_G: 2.6902\n",
            "Epoch 37, Batch 400, Loss_D: 0.3134, Loss_G: 2.3572\n",
            "Epoch 38, Batch 200, Loss_D: 0.3516, Loss_G: 2.5801\n",
            "Epoch 38, Batch 400, Loss_D: 0.2465, Loss_G: 2.1535\n",
            "Epoch 39, Batch 200, Loss_D: 0.2534, Loss_G: 1.9968\n",
            "Epoch 39, Batch 400, Loss_D: 0.3019, Loss_G: 3.7607\n",
            "Epoch 40, Batch 200, Loss_D: 0.3666, Loss_G: 3.0278\n",
            "Epoch 40, Batch 400, Loss_D: 0.3055, Loss_G: 2.2197\n",
            "Epoch 41, Batch 200, Loss_D: 0.3444, Loss_G: 2.6894\n",
            "Epoch 41, Batch 400, Loss_D: 0.2853, Loss_G: 2.6952\n",
            "Epoch 42, Batch 200, Loss_D: 0.2300, Loss_G: 2.1017\n",
            "Epoch 42, Batch 400, Loss_D: 0.3911, Loss_G: 3.5826\n",
            "Epoch 43, Batch 200, Loss_D: 0.3343, Loss_G: 1.4875\n",
            "Epoch 43, Batch 400, Loss_D: 0.3729, Loss_G: 1.6500\n",
            "Epoch 44, Batch 200, Loss_D: 0.3978, Loss_G: 2.7219\n",
            "Epoch 44, Batch 400, Loss_D: 0.3390, Loss_G: 1.6377\n",
            "Epoch 45, Batch 200, Loss_D: 0.2299, Loss_G: 2.6625\n",
            "Epoch 45, Batch 400, Loss_D: 0.3513, Loss_G: 1.9927\n",
            "Epoch 46, Batch 200, Loss_D: 0.3169, Loss_G: 1.7114\n",
            "Epoch 46, Batch 400, Loss_D: 0.2805, Loss_G: 2.3009\n",
            "Epoch 47, Batch 200, Loss_D: 0.4059, Loss_G: 3.4036\n",
            "Epoch 47, Batch 400, Loss_D: 0.3822, Loss_G: 1.3094\n",
            "Epoch 48, Batch 200, Loss_D: 0.2810, Loss_G: 2.2303\n",
            "Epoch 48, Batch 400, Loss_D: 0.2722, Loss_G: 2.3953\n",
            "Epoch 49, Batch 200, Loss_D: 0.3393, Loss_G: 1.9085\n",
            "Epoch 49, Batch 400, Loss_D: 0.3204, Loss_G: 1.5340\n",
            "Epoch 50, Batch 200, Loss_D: 0.2476, Loss_G: 2.6858\n",
            "Epoch 50, Batch 400, Loss_D: 0.3708, Loss_G: 3.0749\n",
            "Epoch 51, Batch 200, Loss_D: 0.3568, Loss_G: 2.6106\n",
            "Epoch 51, Batch 400, Loss_D: 0.2525, Loss_G: 2.4339\n",
            "Epoch 52, Batch 200, Loss_D: 0.2640, Loss_G: 2.4429\n",
            "Epoch 52, Batch 400, Loss_D: 0.4103, Loss_G: 1.9585\n",
            "Epoch 53, Batch 200, Loss_D: 0.3779, Loss_G: 2.2651\n",
            "Epoch 53, Batch 400, Loss_D: 0.3503, Loss_G: 2.2362\n",
            "Epoch 54, Batch 200, Loss_D: 0.3539, Loss_G: 2.7092\n",
            "Epoch 54, Batch 400, Loss_D: 0.3541, Loss_G: 1.5627\n",
            "Epoch 55, Batch 200, Loss_D: 0.3201, Loss_G: 2.0601\n",
            "Epoch 55, Batch 400, Loss_D: 0.3721, Loss_G: 1.7660\n",
            "Epoch 56, Batch 200, Loss_D: 0.3041, Loss_G: 2.0020\n",
            "Epoch 56, Batch 400, Loss_D: 0.3524, Loss_G: 1.7527\n",
            "Epoch 57, Batch 200, Loss_D: 0.3054, Loss_G: 1.8709\n",
            "Epoch 57, Batch 400, Loss_D: 0.3318, Loss_G: 2.7355\n",
            "Epoch 58, Batch 200, Loss_D: 0.3396, Loss_G: 2.0225\n",
            "Epoch 58, Batch 400, Loss_D: 0.3855, Loss_G: 2.5859\n",
            "Epoch 59, Batch 200, Loss_D: 0.2425, Loss_G: 2.4338\n",
            "Epoch 59, Batch 400, Loss_D: 0.3665, Loss_G: 1.8206\n",
            "Epoch 60, Batch 200, Loss_D: 0.3762, Loss_G: 2.5126\n",
            "Epoch 60, Batch 400, Loss_D: 0.3400, Loss_G: 1.7950\n",
            "Epoch 61, Batch 200, Loss_D: 0.3349, Loss_G: 1.9839\n",
            "Epoch 61, Batch 400, Loss_D: 0.3433, Loss_G: 1.8155\n",
            "Epoch 62, Batch 200, Loss_D: 0.4318, Loss_G: 1.3619\n",
            "Epoch 62, Batch 400, Loss_D: 0.4028, Loss_G: 1.5568\n",
            "Epoch 63, Batch 200, Loss_D: 0.2990, Loss_G: 2.8803\n",
            "Epoch 63, Batch 400, Loss_D: 0.3522, Loss_G: 1.9684\n",
            "Epoch 64, Batch 200, Loss_D: 0.4241, Loss_G: 2.8880\n",
            "Epoch 64, Batch 400, Loss_D: 0.3453, Loss_G: 1.5751\n",
            "Epoch 65, Batch 200, Loss_D: 0.3525, Loss_G: 2.5916\n",
            "Epoch 65, Batch 400, Loss_D: 0.3546, Loss_G: 1.5985\n",
            "Epoch 66, Batch 200, Loss_D: 0.3474, Loss_G: 1.4342\n",
            "Epoch 66, Batch 400, Loss_D: 0.3237, Loss_G: 2.4087\n",
            "Epoch 67, Batch 200, Loss_D: 0.3946, Loss_G: 2.8023\n",
            "Epoch 67, Batch 400, Loss_D: 0.3124, Loss_G: 2.1676\n",
            "Epoch 68, Batch 200, Loss_D: 0.3135, Loss_G: 2.3348\n",
            "Epoch 68, Batch 400, Loss_D: 0.3172, Loss_G: 1.7586\n",
            "Epoch 69, Batch 200, Loss_D: 0.3197, Loss_G: 1.6922\n",
            "Epoch 69, Batch 400, Loss_D: 0.3081, Loss_G: 2.1331\n",
            "Epoch 70, Batch 200, Loss_D: 0.3054, Loss_G: 1.5407\n",
            "Epoch 70, Batch 400, Loss_D: 0.2841, Loss_G: 1.8486\n",
            "Epoch 71, Batch 200, Loss_D: 0.3673, Loss_G: 1.9168\n",
            "Epoch 71, Batch 400, Loss_D: 0.3185, Loss_G: 2.2926\n",
            "Epoch 72, Batch 200, Loss_D: 0.2832, Loss_G: 2.0815\n",
            "Epoch 72, Batch 400, Loss_D: 0.3222, Loss_G: 2.1343\n",
            "Epoch 73, Batch 200, Loss_D: 0.4351, Loss_G: 1.9308\n",
            "Epoch 73, Batch 400, Loss_D: 0.4105, Loss_G: 1.2054\n",
            "Epoch 74, Batch 200, Loss_D: 0.3098, Loss_G: 2.9169\n",
            "Epoch 74, Batch 400, Loss_D: 0.2705, Loss_G: 2.2523\n",
            "Epoch 75, Batch 200, Loss_D: 0.4028, Loss_G: 2.1960\n",
            "Epoch 75, Batch 400, Loss_D: 0.3849, Loss_G: 1.7288\n",
            "Epoch 76, Batch 200, Loss_D: 0.3134, Loss_G: 2.2552\n",
            "Epoch 76, Batch 400, Loss_D: 0.4598, Loss_G: 2.8169\n",
            "Epoch 77, Batch 200, Loss_D: 0.4527, Loss_G: 3.3588\n",
            "Epoch 77, Batch 400, Loss_D: 0.2757, Loss_G: 1.9801\n",
            "Epoch 78, Batch 200, Loss_D: 0.2756, Loss_G: 1.8220\n",
            "Epoch 78, Batch 400, Loss_D: 0.3737, Loss_G: 1.3989\n",
            "Epoch 79, Batch 200, Loss_D: 0.3361, Loss_G: 1.5598\n",
            "Epoch 79, Batch 400, Loss_D: 0.2882, Loss_G: 1.2904\n",
            "Epoch 80, Batch 200, Loss_D: 0.1824, Loss_G: 2.4582\n",
            "Epoch 80, Batch 400, Loss_D: 0.3564, Loss_G: 1.7978\n",
            "Epoch 81, Batch 200, Loss_D: 0.2856, Loss_G: 2.7413\n",
            "Epoch 81, Batch 400, Loss_D: 0.2735, Loss_G: 2.1240\n",
            "Epoch 82, Batch 200, Loss_D: 0.2712, Loss_G: 2.5824\n",
            "Epoch 82, Batch 400, Loss_D: 0.4334, Loss_G: 2.3228\n",
            "Epoch 83, Batch 200, Loss_D: 0.3250, Loss_G: 2.3129\n",
            "Epoch 83, Batch 400, Loss_D: 0.2433, Loss_G: 2.3173\n",
            "Epoch 84, Batch 200, Loss_D: 0.3562, Loss_G: 2.4681\n",
            "Epoch 84, Batch 400, Loss_D: 0.3595, Loss_G: 2.5231\n",
            "Epoch 85, Batch 200, Loss_D: 0.4316, Loss_G: 3.8055\n",
            "Epoch 85, Batch 400, Loss_D: 0.3506, Loss_G: 1.6326\n",
            "Epoch 86, Batch 200, Loss_D: 0.2967, Loss_G: 2.7649\n",
            "Epoch 86, Batch 400, Loss_D: 0.3428, Loss_G: 2.7604\n",
            "Epoch 87, Batch 200, Loss_D: 0.3983, Loss_G: 2.6442\n",
            "Epoch 87, Batch 400, Loss_D: 0.4212, Loss_G: 1.4199\n",
            "Epoch 88, Batch 200, Loss_D: 0.3735, Loss_G: 1.7345\n",
            "Epoch 88, Batch 400, Loss_D: 0.3436, Loss_G: 1.8922\n",
            "Epoch 89, Batch 200, Loss_D: 0.2599, Loss_G: 2.4119\n",
            "Epoch 89, Batch 400, Loss_D: 0.2965, Loss_G: 2.0954\n",
            "Epoch 90, Batch 200, Loss_D: 0.4992, Loss_G: 1.9283\n",
            "Epoch 90, Batch 400, Loss_D: 0.5403, Loss_G: 1.2002\n",
            "Epoch 91, Batch 200, Loss_D: 0.5044, Loss_G: 2.6433\n",
            "Epoch 91, Batch 400, Loss_D: 0.2382, Loss_G: 1.9634\n",
            "Epoch 92, Batch 200, Loss_D: 0.3621, Loss_G: 1.4495\n",
            "Epoch 92, Batch 400, Loss_D: 0.2320, Loss_G: 2.3593\n",
            "Epoch 93, Batch 200, Loss_D: 0.4376, Loss_G: 3.3653\n",
            "Epoch 93, Batch 400, Loss_D: 0.2579, Loss_G: 1.8019\n",
            "Epoch 94, Batch 200, Loss_D: 0.3337, Loss_G: 2.0411\n",
            "Epoch 94, Batch 400, Loss_D: 0.3000, Loss_G: 1.7498\n",
            "Epoch 95, Batch 200, Loss_D: 0.3755, Loss_G: 2.3012\n",
            "Epoch 95, Batch 400, Loss_D: 0.2154, Loss_G: 2.2497\n",
            "Epoch 96, Batch 200, Loss_D: 0.2329, Loss_G: 2.4786\n",
            "Epoch 96, Batch 400, Loss_D: 0.5450, Loss_G: 0.9975\n",
            "Epoch 97, Batch 200, Loss_D: 0.4508, Loss_G: 2.9249\n",
            "Epoch 97, Batch 400, Loss_D: 0.2220, Loss_G: 2.8828\n",
            "Epoch 98, Batch 200, Loss_D: 0.3908, Loss_G: 1.3804\n",
            "Epoch 98, Batch 400, Loss_D: 0.3695, Loss_G: 2.2547\n",
            "Epoch 99, Batch 200, Loss_D: 0.5617, Loss_G: 1.4185\n",
            "Epoch 99, Batch 400, Loss_D: 0.3615, Loss_G: 3.0043\n",
            "Epoch 100, Batch 200, Loss_D: 0.2933, Loss_G: 3.2738\n",
            "Epoch 100, Batch 400, Loss_D: 0.3367, Loss_G: 2.3392\n"
          ]
        }
      ],
      "source": [
        "# Train the GAN model\n",
        "for epoch in range(1, num_epochs + 1):\n",
        "    # Loop over the batches in the dataloader\n",
        "    for i, (real_images, _) in enumerate(dataloader):\n",
        "        # Get the batch size from the real images\n",
        "        batch_size = real_images.size(0)\n",
        "        # Move the real images to the device\n",
        "        real_images = real_images.to(device)\n",
        "        # Generate a batch of latent vectors\n",
        "        latent_vectors = generate_latent_vectors(batch_size, latent_dim)\n",
        "        # Generate a batch of fake images using the generator\n",
        "        # Generate a batch of latent vectors\n",
        "        latent_vectors = generate_latent_vectors(batch_size, latent_dim)\n",
        "        # Reshape the latent vectors to match the expected input shape of the generator\n",
        "        latent_vectors = latent_vectors.view(batch_size, latent_dim)\n",
        "        # Generate a batch of fake images using the generator\n",
        "        fake_images = generator(latent_vectors)\n",
        "        # Generate a batch of fake labels\n",
        "        fake_labels = generate_fake_labels(batch_size)\n",
        "        # Generate a batch of real labels\n",
        "        real_labels = generate_real_labels(batch_size)\n",
        "        # Compute the discriminator outputs for the real images and the fake images\n",
        "        output_real = discriminator(real_images).view(-1)\n",
        "        output_fake = discriminator(fake_images.detach()).view(-1)\n",
        "        # Compute the discriminator loss for the real images and the fake images\n",
        "        loss_D_real = criterion(output_real, real_labels)\n",
        "        loss_D_fake = criterion(output_fake, fake_labels)\n",
        "        # Compute the total discriminator loss\n",
        "        loss_D = (loss_D_real + loss_D_fake) / 2\n",
        "        # Zero the gradients of the discriminator parameters\n",
        "        optimizer_D.zero_grad()\n",
        "        # Backpropagate the discriminator loss\n",
        "        loss_D.backward()\n",
        "        # Update the discriminator parameters using the optimizer\n",
        "        optimizer_D.step()\n",
        "        # Compute the generator output for the fake images\n",
        "        output_G = discriminator(fake_images).view(-1)\n",
        "        # Compute the generator loss using the discriminator output\n",
        "        loss_G = criterion(output_G, real_labels)\n",
        "        # Zero the gradients of the generator parameters\n",
        "        optimizer_G.zero_grad()\n",
        "        # Backpropagate the generator loss\n",
        "        loss_G.backward()\n",
        "        # Update the generator parameters using the optimizer\n",
        "        optimizer_G.step()\n",
        "\n",
        "        # Print the losses and save the images every 200 batches\n",
        "        if (i + 1) % 200 == 0:\n",
        "            print(\n",
        "                f\"Epoch {epoch}, Batch {i + 1}, Loss_D: {loss_D.item():.4f}, Loss_G: {loss_G.item():.4f}\"\n",
        "            )\n",
        "            save_images(epoch, generator, dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "L-pI_fmUiEP9"
      },
      "outputs": [],
      "source": [
        "# Save the final images after training\n",
        "save_images(\"final\", generator, dataloader)\n",
        "\n",
        "# Save the generator and discriminator models to files\n",
        "state_dicts = {\n",
        "    \"generator\": generator.state_dict(),\n",
        "    \"discriminator\": discriminator.state_dict(),\n",
        "}\n",
        "\n",
        "torch.save(state_dicts, \"MNIST_GAN.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "NmiTdAhLmOns"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                [-1, 12544]       1,266,944\n",
            "       BatchNorm1d-2                [-1, 12544]          25,088\n",
            "         LeakyReLU-3                [-1, 12544]               0\n",
            "         Unflatten-4            [-1, 256, 7, 7]               0\n",
            "   ConvTranspose2d-5          [-1, 128, 14, 14]         524,416\n",
            "       BatchNorm2d-6          [-1, 128, 14, 14]             256\n",
            "         LeakyReLU-7          [-1, 128, 14, 14]               0\n",
            "   ConvTranspose2d-8           [-1, 64, 28, 28]         131,136\n",
            "       BatchNorm2d-9           [-1, 64, 28, 28]             128\n",
            "        LeakyReLU-10           [-1, 64, 28, 28]               0\n",
            "  ConvTranspose2d-11            [-1, 1, 28, 28]             577\n",
            "             Tanh-12            [-1, 1, 28, 28]               0\n",
            "================================================================\n",
            "Total params: 1,948,545\n",
            "Trainable params: 1,948,545\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 2.12\n",
            "Params size (MB): 7.43\n",
            "Estimated Total Size (MB): 9.55\n",
            "----------------------------------------------------------------\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 64, 14, 14]           1,088\n",
            "         LeakyReLU-2           [-1, 64, 14, 14]               0\n",
            "            Conv2d-3            [-1, 128, 7, 7]         131,200\n",
            "       BatchNorm2d-4            [-1, 128, 7, 7]             256\n",
            "         LeakyReLU-5            [-1, 128, 7, 7]               0\n",
            "           Flatten-6                 [-1, 6272]               0\n",
            "            Linear-7                    [-1, 1]           6,273\n",
            "           Sigmoid-8                    [-1, 1]               0\n",
            "================================================================\n",
            "Total params: 138,817\n",
            "Trainable params: 138,817\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.38\n",
            "Params size (MB): 0.53\n",
            "Estimated Total Size (MB): 0.92\n",
            "----------------------------------------------------------------\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\PC\\AppData\\Local\\Temp\\ipykernel_15500\\794719855.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(\"MNIST_GAN.pt\")\n"
          ]
        }
      ],
      "source": [
        "# Load the state dicts into your models\n",
        "checkpoint = torch.load(\"MNIST_GAN.pt\")\n",
        "generator.load_state_dict(checkpoint[\"generator\"])\n",
        "discriminator.load_state_dict(checkpoint[\"discriminator\"])\n",
        "\n",
        "summary(generator, input_size=(100,))\n",
        "summary(discriminator, input_size=(1, 28, 28))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "vHSs_ReT6L59"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Generator(\n",
              "  (main): Sequential(\n",
              "    (0): Linear(in_features=100, out_features=12544, bias=True)\n",
              "    (1): BatchNorm1d(12544, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (2): LeakyReLU(negative_slope=0.2)\n",
              "    (3): Unflatten(dim=1, unflattened_size=(256, 7, 7))\n",
              "    (4): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (6): LeakyReLU(negative_slope=0.2)\n",
              "    (7): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
              "    (8): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "    (9): LeakyReLU(negative_slope=0.2)\n",
              "    (10): ConvTranspose2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "    (11): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Switch the generator to evaluation mode\n",
        "generator.eval()  # This is crucial to ensure BatchNorm uses running mean/variance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "Wtevx_jiSCeW"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x800 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Prepare your noise vector\n",
        "noise = torch.randn(1, 100).to(\"cuda\")\n",
        "\n",
        "# Generate an image\n",
        "with torch.no_grad():\n",
        "    # Pass noise through the generator\n",
        "    # It will reshape internally as per the generator's architecture\n",
        "    fake_image = generator(noise)\n",
        "\n",
        "# Convert the grid of images to a numpy array and squeeze to drop any unit dimensions\n",
        "ndarr = fake_image.cpu().squeeze().numpy()\n",
        "\n",
        "# Plot the single image\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.imshow(ndarr, cmap=\"gray\", interpolation=\"nearest\")  # Grayscale image\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "ganworks",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
